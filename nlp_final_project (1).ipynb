{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Installing dependencies\n"
      ],
      "metadata": {
        "id": "PjOyo3DXq7Ew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQa_YTvyoanF",
        "outputId": "b962b2dc-bc14-4215-be83-a3ca01b14e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/179.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU \\\n",
        "  pinecone-client \\\n",
        "  sentence-transformers==2.2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Open knowledge base dataset and format appropriately"
      ],
      "metadata": {
        "id": "woLgWpv--qbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/knowledge-base.jsonList\", 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "formatted_data = list(map(lambda entry: f\"{entry}: class {data[entry]}\", data))\n",
        "\n",
        "print(formatted_data[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5JaEal8-pBl",
        "outputId": "51b83e9a-258e-48ec-d497-7bc86de6ef38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ready-to-eat meals: class I', 'Canned goods: class I', 'Energy bars: class I', 'Crackers and biscuits: class I', 'Trail mix: class I']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Generate embeddings from knowledge base\n"
      ],
      "metadata": {
        "id": "Ohu-2yWFri0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "embeddings = [{'id': str(idx), 'values': model.encode(sentence).tolist(), 'metadata': {'text': sentence}} for idx, sentence in enumerate(formatted_data)]\n",
        "\n",
        "dimensions = len(embeddings[0]['values'])\n",
        "print(f'Embedding dimensions: {dimensions}')\n",
        "print(embeddings[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc8VlQoBsLzt",
        "outputId": "5f9037fd-0597-4956-836d-1d7fa38412f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimensions: 384\n",
            "[{'id': '0', 'values': [-0.018903309479355812, 0.014547097496688366, 0.0018049427308142185, 0.07448364794254303, -0.07618480175733566, 0.02340506762266159, 0.028933241963386536, -0.07292620092630386, -0.05023764818906784, 0.0039814976043999195, 0.0321856290102005, -0.0010382087202742696, -0.057538967579603195, -0.043087951838970184, 0.02150295116007328, -0.07702628523111343, 0.15172737836837769, -0.09067443013191223, -0.020970914512872696, 0.004081401042640209, -0.030665768310427666, 0.05587448179721832, 0.006449646782130003, 0.02709435671567917, -0.006290411576628685, 0.00036694499431177974, 0.08656466007232666, -0.06687478721141815, -0.024677075445652008, -0.03569306805729866, -0.032425571233034134, -0.033530570566654205, 0.04410792514681816, 0.030293527990579605, -0.06449401378631592, 0.07058001309633255, 0.13439196348190308, -0.040091607719659805, -0.037033457309007645, 0.016013646498322487, -0.01172659732401371, -0.08185499906539917, -0.0439860038459301, 0.0073859188705682755, 0.012815705500543118, -0.0012387922033667564, -0.0640590712428093, 0.042496971786022186, 0.016258439049124718, -0.010775207541882992, -0.10422442853450775, -0.01994595117866993, -0.05713368579745293, -0.02381056547164917, 0.07454659044742584, 0.04701760783791542, -0.009990225546061993, -0.03931904211640358, -0.07892753928899765, -0.005369688384234905, -0.08581814914941788, -0.021647389978170395, -0.017161482945084572, 0.02607175149023533, 0.013195634819567204, -0.009883909486234188, -0.043418072164058685, 0.05392349511384964, -0.02905621938407421, 0.066925048828125, -0.03665362298488617, 0.029750220477581024, 0.05258921906352043, 0.03297977149486542, -0.0028369601350277662, -0.018221698701381683, 0.04300995543599129, -0.06892384588718414, -0.008890601806342602, -0.035799212753772736, 0.0061195166781544685, 0.03767576441168785, 0.06287022680044174, 0.014635678380727768, -0.02381560392677784, 0.030884698033332825, -0.00939763244241476, 0.06220860034227371, -1.20546528705745e-05, -0.02598603069782257, -0.025616561993956566, -0.025767870247364044, -0.035828880965709686, 0.016012834385037422, -0.03258437663316727, 0.0652487725019455, -0.07858308404684067, -0.1439601629972458, 0.0007912403671070933, 0.045940883457660675, 0.013553748838603497, 0.04852316528558731, 0.026852859184145927, 0.05963759124279022, -0.02567330002784729, -0.07998936623334885, -0.008250373415648937, 0.060368798673152924, -4.0713101043365896e-05, 0.0037486799992620945, 0.02435421384871006, -0.009646488353610039, -0.0458725206553936, -0.0062883151695132256, -0.06176067888736725, 0.032103851437568665, 0.060081083327531815, -0.07759342342615128, 0.05414838343858719, -0.00999719649553299, 0.0020415843464434147, 0.05053906515240669, -0.016113940626382828, -0.08552487194538116, -0.05144939199090004, -0.09414537250995636, 0.0030909257475286722, -5.25301278809816e-33, -0.024748314172029495, -0.05944838002324104, 0.050873417407274246, 0.13595940172672272, -0.001986935269087553, -0.04070281982421875, 0.006017747335135937, -0.03271161764860153, 0.04399232193827629, 0.05243931710720062, 0.06005857139825821, -0.028399595990777016, -0.014275887981057167, 0.08202230930328369, 0.024932991713285446, -0.045185353606939316, -0.06695246696472168, 0.04471299797296524, 0.0402088388800621, 0.05415206030011177, -0.028592636808753014, -0.06712795794010162, 0.05355123430490494, -0.03398645669221878, 0.025783730670809746, 0.07357960194349289, -0.05797673016786575, -0.03442737087607384, -0.01765078492462635, 0.027121884748339653, 0.03221090883016586, -0.03342890366911888, -0.07463443279266357, -0.0880822166800499, -0.04696524888277054, -0.0008029551827348769, -0.01587524078786373, -0.010266803205013275, -0.013316649943590164, -0.05328728258609772, 0.03333050012588501, 0.008998735807836056, 0.025413915514945984, 0.022024963051080704, -0.06482623517513275, 0.016879258677363396, -0.020242847502231598, 0.05350767448544502, -0.0035225271712988615, 0.051242928951978683, -0.028770100325345993, -0.05454332381486893, 0.00813967827707529, -0.07624617218971252, -0.09949377924203873, -0.003098259214311838, 0.04865036904811859, 0.024449942633509636, -0.04738662764430046, 0.011023487895727158, 0.005828701425343752, 0.0789717584848404, -0.0393686443567276, -0.01751967892050743, -0.0443728044629097, -0.007882120087742805, -0.04886038228869438, -0.08006195724010468, 0.028798263520002365, -0.03637601062655449, -0.01018346007913351, -0.05635562166571617, -0.007212539203464985, 0.040038369596004486, 0.07499678432941437, 0.0012156869051977992, -0.011143393814563751, -0.040814440697431564, -0.06330413371324539, -0.0031685344874858856, 0.18302613496780396, -0.024654272943735123, 0.025128765031695366, 0.047453779727220535, 0.0047640311531722546, 0.060459040105342865, -0.03475392609834671, -0.05463482066988945, 0.11933353543281555, 0.06292561441659927, -0.0698435828089714, 0.01654748059809208, 0.06491167098283768, 0.03545916825532913, -0.08885267376899719, 2.826097620637027e-33, 0.09693092852830887, -0.009079553186893463, -0.11516691744327545, 0.09264250099658966, 0.020398272201418877, -0.041485436260700226, -0.013414501212537289, -0.03353342041373253, -0.03183905780315399, -0.006202330347150564, -0.02466038055717945, 0.032812558114528656, 0.007944843731820583, -0.07336387783288956, 0.025596968829631805, 0.06500378251075745, 0.0576830729842186, 0.0005855686613358557, 0.010313797742128372, 0.013818581588566303, -0.0547248050570488, -0.029251009225845337, 0.013170146383345127, -0.03559080511331558, -0.03599712252616882, 0.0828646793961525, 0.04662269353866577, 0.09898927062749863, -0.0569879524409771, -0.03547482192516327, 0.030872611328959465, -0.07058901339769363, 0.0458405427634716, -0.04622926190495491, -0.010398026555776596, 0.09629648923873901, -0.08846171200275421, -0.01659424602985382, -0.011841429397463799, 0.08129298686981201, 0.09945545345544815, -0.01608719862997532, -0.061445869505405426, 0.0655663013458252, -0.05000694468617439, -0.039788853377103806, 0.06592576205730438, 0.003174453740939498, -0.035071875900030136, 0.037746183574199677, -0.017877385020256042, -0.009108290076255798, 0.03169582411646843, -0.06880711019039154, 0.06796471029520035, 0.030196238309144974, 0.016158094629645348, -0.0628378838300705, 0.011053215712308884, -0.02117091789841652, -0.08212149143218994, 0.02149144373834133, 0.03752594441175461, 0.018927529454231262, 0.040219299495220184, -0.05872134491801262, -0.00025806069606915116, -0.04343119636178017, 0.004379858262836933, 0.015378264710307121, -0.016950029879808426, -0.010370572097599506, 0.005955402739346027, -0.020180227234959602, -0.026952696964144707, -0.022082868963479996, 0.002138015115633607, 0.018377836793661118, -0.004062781576067209, -0.00807525496929884, -0.09498438239097595, -0.07457337528467178, -0.02537020482122898, 0.04835638031363487, 0.06696287542581558, 0.06696133315563202, 0.006134808529168367, -0.00010830468818312511, 0.011621970683336258, 0.10522790998220444, -0.024096855893731117, 0.05371137708425522, 0.09914456307888031, 0.052917949855327606, 0.07340698689222336, -1.785762471229191e-08, 0.09583001583814621, -0.08885233849287033, -0.04474836215376854, 0.0711715966463089, 0.034682516008615494, -0.061363086104393005, -0.016623681411147118, -0.06570027768611908, -0.0002703845966607332, 0.08803240209817886, -0.024843081831932068, 0.10238640755414963, 0.08126595616340637, 0.007318634074181318, -0.04332408308982849, 0.050764743238687515, 0.0016917971661314368, 0.028314778581261635, -0.08727934956550598, 0.04296223446726799, -0.008076857775449753, -0.027060000225901604, -0.013239683583378792, -0.06242990121245384, 0.11543992906808853, -0.01902649737894535, 0.05968846380710602, 0.033835891634225845, 0.03877623379230499, 0.053493909537792206, 0.02461780421435833, 0.05424497276544571, -0.06641199439764023, 0.004140421748161316, 0.07078003883361816, -0.04616890847682953, -0.02231491543352604, 0.03182995691895485, -0.005338177550584078, -0.08683863282203674, -0.08233170211315155, -0.07869618386030197, 0.010935199446976185, 0.0349905751645565, -0.01789986900985241, 0.07893668115139008, -0.09189106523990631, 0.041684556752443314, 0.018433723598718643, 0.02361125499010086, -0.07099344581365585, 0.041321709752082825, 0.0505252480506897, 0.04471174255013466, -0.014456838369369507, 0.05392426624894142, 0.053242795169353485, -0.055980145931243896, 0.08961313962936401, -0.008840970695018768, 0.020182451233267784, 0.07273992896080017, -0.05553141236305237, -0.0344175361096859], 'metadata': {'text': 'Ready-to-eat meals: class I'}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Upsert embeddings to Pinecone"
      ],
      "metadata": {
        "id": "0_q_kBzHCkVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "pinecone.init(api_key=\"your-pinecone-api-key\", environment=\"your-pod-env\")\n",
        "index = pinecone.Index(\"your-index\")\n",
        "\n",
        "response = index.upsert(embeddings)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE2Ej1LNCqma",
        "outputId": "30afd957-ecb8-4e76-a170-6bded28e386c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'upserted_count': 320}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Load test dataset"
      ],
      "metadata": {
        "id": "xnp5ORUEJ2uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/test-data.jsonList', 'r') as file:\n",
        "    test_data = json.load(file)"
      ],
      "metadata": {
        "id": "XNFcYgoe-_Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Classifying test data with gpt-3.5-turbo-16k:\n",
        "- Define system message.\n",
        "- For each entry in test dataset\n",
        "  1.   Retrieve similar examples from Pinecone\n",
        "  2.   Prompt model using COT.\n",
        "  3.   Await response and push to list"
      ],
      "metadata": {
        "id": "E125Gqz1_O1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys_msg_cot = f'''\n",
        "You are a helpful assistant that classifies supplies into an appropriate class (I, II, III, IV, V, VI, VII, VIII, IX, X).\n",
        "\n",
        "Furthermore, you know that the guidelines for assigning a class are the following:\n",
        "Class I – Rations – Subsistence (food and drinking water), gratuitous (free) health and comfort items.\n",
        "Class II – Clothing And Equipment – individual equipment, tentage, some aerial delivery equipment, organizational tool sets and kits, hand tools, unclassified maps, administrative and housekeeping supplies and equipment.\n",
        "Class III – POL – Petroleum, Oil and Lubricants (POL) (package and bulk): Petroleum, fuels, lubricants, hydraulic and insulating oils, preservatives, liquids and gases, bulk chemical products, coolants, deicer and antifreeze compounds, components, and additives of petroleum and chemical products, and coal.\n",
        "Class IV – Construction materials, including installed equipment and all fortification and barrier materials.\n",
        "Class V – Ammunition of all types, bombs, explosives, mines, fuses, detonators, pyrotechnics, missiles, rockets, propellants, and associated items.\n",
        "Class VI – Personal demand items (such as health and hygiene products, soaps and toothpaste, writing material, snack food, beverages, cigarettes, batteries, alcohol, and cameras—nonmilitary sales items).\n",
        "Class VII – Major end items such as launchers, tanks, mobile machine shops, some parachute systems and vehicles.\n",
        "Class VIII – Medical material (equipment and consumables) including repair parts particular to medical equipment. (Class VIIIa – Medical consumable supplies not including blood & blood products; Class VIIIb – Blood & blood components (whole blood, platelets, plasma, packed red cells, etc.).\n",
        "Class IX – Repair parts and components to include kits, assemblies, and subassemblies (repairable or non-repairable) required for maintenance support of all equipment.\n",
        "Class X – Material to support nonmilitary programs such as agriculture and economic development (not included in Classes I through IX).\n",
        "Miscellaneous – Water, salvage, and captured material.\n",
        "'''\n",
        "\n",
        "sys_msg_tot = f'''\n",
        "You are a helpful assistant that classifies supplies into an appropriate class (I, II, III, IV, V, VI, VII, VIII, IX, X).\n",
        "\n",
        "When you answer, imagine two different experts are answering this question. Both experts will consider the examples provided by the user, class guidelines, and item characteristics. They will write down one step of their thinking and then share it with the group. When one expert realizes they made a mistake, they will backtrack and explore other possible solution paths. Finally, all experts will agree on a result. For example:\n",
        "\n",
        "User asks: \"Given that Jerry Cans are class II, classify Tuna Cans\".\n",
        "\n",
        "You answer:\n",
        "\"Expert 1: Cans can be considered equipment, indicating class II.\n",
        "Expert 2: Tuna indicates that we are dealing with food, indicating this could be class II.\n",
        "Expert 1: I see my mistake; these are tuna cans, which means their purpose is to provide food. This indicates we are dealing with class I rations.\n",
        "Expert 2: We could also be dealing with class VI (personal items like snacks), but tuna is not usually eaten as a snack, which indicates this item is class I.\n",
        "All experts agree that this item is class I.\"\n",
        "\n",
        "Furthermore, you know that the guidelines for assigning a class are the following:\n",
        "Class I – Rations – Subsistence (food and drinking water), gratuitous (free) health and comfort items.\n",
        "Class II – Clothing And Equipment – individual equipment, tentage, some aerial delivery equipment, organizational tool sets and kits, hand tools, unclassified maps, administrative and housekeeping supplies and equipment.\n",
        "Class III – POL – Petroleum, Oil and Lubricants (POL) (package and bulk): Petroleum, fuels, lubricants, hydraulic and insulating oils, preservatives, liquids and gases, bulk chemical products, coolants, deicer and antifreeze compounds, components, and additives of petroleum and chemical products, and coal.\n",
        "Class IV – Construction materials, including installed equipment and all fortification and barrier materials.\n",
        "Class V – Ammunition of all types, bombs, explosives, mines, fuses, detonators, pyrotechnics, missiles, rockets, propellants, and associated items.\n",
        "Class VI – Personal demand items (such as health and hygiene products, soaps and toothpaste, writing material, snack food, beverages, cigarettes, batteries, alcohol, and cameras—nonmilitary sales items).\n",
        "Class VII – Major end items such as launchers, tanks, mobile machine shops, some parachute systems and vehicles.\n",
        "Class VIII – Medical material (equipment and consumables) including repair parts particular to medical equipment. (Class VIIIa – Medical consumable supplies not including blood & blood products; Class VIIIb – Blood & blood components (whole blood, platelets, plasma, packed red cells, etc.).\n",
        "Class IX – Repair parts and components to include kits, assemblies, and subassemblies (repairable or non-repairable) required for maintenance support of all equipment.\n",
        "Class X – Material to support nonmilitary programs such as agriculture and economic development (not included in Classes I through IX).\n",
        "Miscellaneous – Water, salvage, and captured material.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "MShmBGMlFV7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijnPSJM7GPGw",
        "outputId": "769ef4b5-e22b-4db1-ac45-354f8c6c440c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/221.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='your-openai-api-key')\n",
        "\n",
        "\n",
        "def prompt_model(item, examples, cot):\n",
        "  cot_prompt = f'Make sure to explain your reasoning while you think, step by step'\n",
        "  prompt = f'Consider these examples: {examples[0]}, {examples[1]} and {examples[2]}. Please classify {item} accordingly.'\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"your-model-goes-here\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": sys_msg_cot if cot else sys_msg_tot},\n",
        "          {\"role\": \"user\", \"content\": prompt + cot_prompt if cot else prompt}\n",
        "      ]\n",
        "  )\n",
        "  return response"
      ],
      "metadata": {
        "id": "a5vOWOwMAhem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_class_from_response(text):\n",
        "    # Find all instances of the word \"class\" in the text\n",
        "    class_positions = [match.end() for match in re.finditer(r'\\bclass\\b', text, flags=re.IGNORECASE)]\n",
        "\n",
        "    # If there are no occurrences of \"class\", return None\n",
        "    if not class_positions:\n",
        "        return None\n",
        "\n",
        "    # Find the position of the last occurrence of \"class\"\n",
        "    last_class_position = max(class_positions)\n",
        "\n",
        "    # Extract any sequence of roman numerals after the last \"class\" occurrence\n",
        "    match = re.search(r'\\b(?:I|II|III|IV|V|VI|VII|VIII|IX|X)+\\b', text[last_class_position:])\n",
        "    if match:\n",
        "        return match.group()\n",
        "\n",
        "    # If no roman numerals are found after the last \"class\", return None\n",
        "    return None"
      ],
      "metadata": {
        "id": "BMjJbo72HAPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pinecone\n",
        "import torch\n",
        "import time\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "pinecone.init(api_key=\"\", environment=\"gcp-starter\")\n",
        "\n",
        "index = pinecone.Index(\"nlp-final-project\")\n",
        "\n",
        "def test(data, cot):\n",
        "\n",
        "  predictions = []\n",
        "\n",
        "  for key in test_data:\n",
        "    query = model.encode(key).tolist()\n",
        "    query_results = index.query(query, top_k=3, include_metadata=True, include_values=True)\n",
        "\n",
        "\n",
        "    examples = list(map(lambda result: result['metadata']['text'], query_results['matches']))\n",
        "\n",
        "    gpt_response = prompt_model(key, examples, cot)\n",
        "    result = gpt_response.choices[0].message.content\n",
        "\n",
        "    label = get_class_from_response(result)\n",
        "    predictions.append(label)\n",
        "\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "5Rm-QLmwHGoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_cot = test(test_data, True)\n",
        "predictions_tot = test(test_data, False)\n",
        "\n",
        "print(predictions_cot)\n",
        "print(predictions_tot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybdyB1u7jp_Q",
        "outputId": "df2dfd26-1ccb-4da7-a2b8-46af449591bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', None, 'I', 'I', 'I', 'II', 'VII', 'VIII', 'X', 'VI', 'III', 'X', None, 'III', 'III', 'IV', 'IV', 'IV', 'IV', 'IV', 'V', 'V', 'V', 'V', 'V', 'VI', 'VI', 'I', 'VI', 'VI', 'VII', 'II', 'VII', 'VII', 'VII', None, 'VIII', None, None, None, 'IX', 'IX', 'II', 'IX', 'X', 'X', 'X', 'X', 'I', None]\n",
            "['I', 'VI', 'I', 'I', 'I', 'II', 'II', 'II', 'VII', None, 'III', 'III', 'III', 'III', 'III', 'IV', 'IV', 'IV', 'IV', 'IV', 'V', 'V', 'V', 'V', 'V', 'VI', 'I', 'VII', 'VI', 'VI', 'VII', 'II', 'VII', 'IV', 'VII', 'I', 'VIII', None, None, None, 'IX', 'III', 'IX', 'IX', 'IX', 'X', 'X', 'X', 'X', 'II']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def correctness(predictions, data):\n",
        "    clean_predictions = []\n",
        "    clean_y_true = []\n",
        "\n",
        "    for pred, true_label in zip(predictions, data.values()):\n",
        "        if pred is None:\n",
        "            continue\n",
        "\n",
        "        clean_predictions.append(pred)\n",
        "        clean_y_true.append(true_label)\n",
        "\n",
        "    accuracy = accuracy_score(clean_y_true, clean_predictions)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score\n",
        "    precision = precision_score(clean_y_true, clean_predictions, average='weighted', zero_division=1)\n",
        "    recall = recall_score(clean_y_true, clean_predictions, average='weighted', zero_division=1)\n",
        "    f1 = f1_score(clean_y_true, clean_predictions, average='weighted', zero_division=1)\n",
        "\n",
        "    return {\n",
        "        'accuracy': round(accuracy * 100, 2),\n",
        "        'precision': round(precision * 100, 2),\n",
        "        'recall': round(recall * 100, 2),\n",
        "        'f1_score': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "JyLHLt8jPxuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correctness_cot = correctness(predictions_cot, test_data)\n",
        "print(f'Correctness using COT prompting: {correctness_cot}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp3RfwURSxFz",
        "outputId": "bfc224a7-4ec4-4437-c632-a1e0d4c2103b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctness using COT prompting: {'accuracy': 74.42, 'precision': 79.84, 'recall': 74.42, 'f1_score': 0.7448504983388705}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correctness_tot = correctness(predictions_tot, test_data)\n",
        "print(f'Correctness using TOT prompting: {correctness_tot}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjSQBj1kTIHt",
        "outputId": "5e032e7e-8beb-4208-ebd9-b44b6a505c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctness using TOT prompting: {'accuracy': 78.26, 'precision': 82.21, 'recall': 78.26, 'f1_score': 0.7742643829600351}\n"
          ]
        }
      ]
    }
  ]
}